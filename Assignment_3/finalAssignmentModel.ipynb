{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Import the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import os\n",
    "import imblearn\n",
    "from imblearn.pipeline import make_pipeline as make_pipeline_imbfinal \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB \n",
    "#from sklearn import svm\n",
    "from sklearn.metrics import *\n",
    "import zipfile\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO\n",
    "import sys\n",
    "import glob\n",
    "import datetime\n",
    "import time\n",
    "import boto.s3\n",
    "from boto.s3.key import Key \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-c7f2cf6900e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"https://s3.amazonaws.com/assignment3datasets/creditcard.csv.zip\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mzipfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'file' is not defined"
     ]
    }
   ],
   "source": [
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "from urllib.request import urlopen\n",
    "# or: requests.get(url).content\n",
    "\n",
    "def get_zip('https://s3.amazonaws.com/assignment3datasets/creditcard.csv.zip'):\n",
    "    url = requests.get(file_url)\n",
    "    zipfile = ZipFile(BytesIO(url.content))\n",
    "    zip_names = zipfile.namelist()\n",
    "    if len(zip_names) == 1:\n",
    "        file_name = zip_names.pop()\n",
    "        extracted_file = zipfile.open(file_name)\n",
    "        return extracted_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##reading the data\n",
    "dataset = pd.read_csv('G://Assignment 3//creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yo2\n"
     ]
    }
   ],
   "source": [
    "##entitling X and Y\n",
    "data = (dataset)\n",
    "print(\"yo2\")\n",
    "X = data[['V1','V2','V3','V4','V5','V6','V7','V9','V10','V11','V12','V14','V16','V17','V18','V19','V21']]\n",
    "Y = data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda32\\lib\\site-packages\\sklearn\\utils\\deprecation.py:77: DeprecationWarning: Function _ratio_float is deprecated; Use a float for 'ratio' is deprecated from version 0.2. The support will be removed in 0.4. Use a dict, str, or a callable instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "## Oversampling\n",
    "sm = SMOTE(random_state=12, ratio = 1.0)\n",
    "x_res, y_res = sm.fit_sample(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Split the dataset into 80:20\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=np.random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Array of accuracy and error metric\n",
    "accuracy =[]\n",
    "model_name =[]\n",
    "f1score = []\n",
    "precision = []\n",
    "recall = []\n",
    "true_positive =[]\n",
    "false_positive =[]\n",
    "true_negative =[]\n",
    "false_negative =[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "## fitiing the model\n",
    "logreg.fit(X_train, Y_train)\n",
    "filename = 'logreg_model.pckl'\n",
    "pickle.dump(logreg,open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = logreg.predict(X_train)\n",
    "f1 = f1_score(Y_train, prediction)\n",
    "p = precision_score(Y_train, prediction)\n",
    "r = recall_score(Y_train, prediction)\n",
    "a = accuracy_score(Y_train, prediction)\n",
    "cm = confusion_matrix(Y_train, prediction)\n",
    "tp = cm[0][0]\n",
    "fp = cm[0][1]\n",
    "fn = cm[1][0]\n",
    "tn = cm[1][1]\n",
    "model_name.append('Logreg')\n",
    "f1score.append(f1)\n",
    "precision.append(p)\n",
    "recall.append(r)\n",
    "accuracy.append(a)\n",
    "true_positive.append(tp) \n",
    "false_positive.append(fp)\n",
    "true_negative.append(fn) \n",
    "false_negative.append(tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NB = BernoulliNB()\n",
    "## fitiing the model\n",
    "NB.fit(X_train, Y_train)\n",
    "filename = 'NB_model.pckl'\n",
    "pickle.dump(NB,open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = NB.predict(X_train)\n",
    "f1 = f1_score(Y_train, prediction)\n",
    "p = precision_score(Y_train, prediction)\n",
    "r = recall_score(Y_train, prediction)\n",
    "a = accuracy_score(Y_train, prediction)\n",
    "cm = confusion_matrix(Y_train, prediction)\n",
    "tp = cm[0][0]\n",
    "fp = cm[0][1]\n",
    "fn = cm[1][0]\n",
    "tn = cm[1][1]\n",
    "model_name.append('NB')\n",
    "f1score.append(f1)\n",
    "precision.append(p)\n",
    "recall.append(r)\n",
    "accuracy.append(a)\n",
    "true_positive.append(tp) \n",
    "false_positive.append(fp)\n",
    "true_negative.append(fn) \n",
    "false_negative.append(tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=50,random_state=0)\n",
    "## fitiing the model\n",
    "rfc.fit(X_train, Y_train)\n",
    "filename = 'rfc_model.pckl'\n",
    "pickle.dump(rfc,open(filename,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = rfc.predict(X_train)\n",
    "f1 = f1_score(Y_train, prediction)\n",
    "p = precision_score(Y_train, prediction)\n",
    "r = recall_score(Y_train, prediction)\n",
    "a = accuracy_score(Y_train, prediction)\n",
    "cm = confusion_matrix(Y_train, prediction)\n",
    "tp = cm[0][0]\n",
    "fp = cm[0][1]\n",
    "fn = cm[1][0]\n",
    "tn = cm[1][1]\n",
    "model_name.append('RFC')\n",
    "f1score.append(f1)\n",
    "precision.append(p)\n",
    "recall.append(r)\n",
    "accuracy.append(a)\n",
    "true_positive.append(tp) \n",
    "false_positive.append(fp)\n",
    "true_negative.append(fn) \n",
    "false_negative.append(tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy and error metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.71274961597542252, 0.70605612998522904, 1.0]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8854961832061069, 0.82986111111111116, 1.0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.99917926660668432, 0.99912659922315605, 1.0]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.59640102827763497, 0.61439588688946012, 1.0]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[227426, 227407, 227456]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30, 49, 0]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[157, 150, 0]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[232, 239, 389]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_negative "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary2 = model_name,f1score,precision,recall,accuracy,true_positive,false_positive,true_negative,false_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Logreg', 'NB', 'RFC'],\n",
       " [0.71274961597542252, 0.70605612998522904, 1.0],\n",
       " [0.8854961832061069, 0.82986111111111116, 1.0],\n",
       " [0.59640102827763497, 0.61439588688946012, 1.0],\n",
       " [0.99917926660668432, 0.99912659922315605, 1.0],\n",
       " [227426, 227407, 227456],\n",
       " [30, 49, 0],\n",
       " [157, 150, 0],\n",
       " [232, 239, 389])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Making a dataframe of the accuracy and error metrics\n",
    "describe1 = pd.DataFrame(summary2[0],columns = {\"Model_Name\"})\n",
    "describe2 = pd.DataFrame(summary2[1],columns = {\"F1_score\"})\n",
    "describe3 = pd.DataFrame(summary2[2],columns = {\"Precision_score\"})\n",
    "describe4 = pd.DataFrame(summary2[3],columns = {\"Recall_score\"})\n",
    "describe3 = pd.DataFrame(summary2[4], columns ={\"Accuracy_score\"})\n",
    "describe5 = pd.DataFrame(summary2[5], columns ={\"True_Positive\"})\n",
    "describe6 = pd.DataFrame(summary2[6], columns ={\"False_Positive\"})\n",
    "describe7 = pd.DataFrame(summary2[7], columns ={\"True_Negative\"})\n",
    "describe8 = pd.DataFrame(summary2[8], columns ={\"False_Negative\"})\n",
    "des = describe1.merge(describe2, left_index=True, right_index=True, how='inner')\n",
    "des = des.merge(describe3,left_index=True, right_index=True, how='inner')\n",
    "des = des.merge(describe4,left_index=True, right_index=True, how='inner')\n",
    "des = des.merge(describe5,left_index=True, right_index=True, how='inner')\n",
    "des = des.merge(describe6,left_index=True, right_index=True, how='inner')\n",
    "des = des.merge(describe7,left_index=True, right_index=True, how='inner')\n",
    "des = des.merge(describe8,left_index=True, right_index=True, how='inner')\n",
    "#des = des.merge(describe9,left_index=True, right_index=True, how='inner')\n",
    "final_csv = des.sort_values(ascending=False,by=\"Accuracy_score\").reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Exporting the metrics in a csv file\n",
    "final_csv.to_csv(str(os.getcwd()) + \"/accuracy_error_metrics1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Loading the pickle file\n",
    "logistic_reg_model = pickle.load(open(filename, 'rb'))\n",
    "Random_forest_classifier_model = pickle.load(open(filename, 'rb'))\n",
    "BernoulliNB_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Zipping the file\n",
    "def zipping(path, ziph):\n",
    "    ziph.write(os.path.join('logistic_reg_model.pckl'))\n",
    "    ziph.write(os.path.join('Random_forest_classifier_model.pckl'))\n",
    "    ziph.write(os.path.join('NB_model.pckl '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zf = zipfile.ZipFile('ABC.zip', 'w')\n",
    "zipping('/', zf)\n",
    "zf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to S3\n",
      "ABC.zip\n",
      "Created S3 bucket successfully\n",
      "..File successfully uploaded to S3\n",
      ".."
     ]
    },
    {
     "data": {
      "text/plain": [
       "305"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Uploading to s3\n",
    "from boto.s3.key import Key\n",
    "\n",
    "accessKey = 'AKIAJLQJ4YCLP3IRRN4A'\n",
    "secretAccessKey ='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'\n",
    "\n",
    "if not accessKey or not secretAccessKey:\n",
    "    print('Access Key and Secret Access Key not provided!!')\n",
    "    exit()\n",
    "\n",
    "AWS_ACCESS_KEY_ID = accessKey\n",
    "AWS_SECRET_ACCESS_KEY = secretAccessKey\n",
    "try:\n",
    "    conn = boto.connect_s3(AWS_ACCESS_KEY_ID,\n",
    "            AWS_SECRET_ACCESS_KEY)\n",
    "\n",
    "    print(\"Connected to S3\")\n",
    "\n",
    "except:\n",
    "    print(\"Amazon keys are invalid!!\")\n",
    "    exit()\n",
    "\n",
    "#ts = time.time()\n",
    "#st = datetime.datetime.fromtimestamp(ts)    \n",
    "bucket_name1 = 'zi101'\n",
    "bucket1 = conn.create_bucket(bucket_name1)\n",
    "\n",
    "#ts = time.time()\n",
    "#st = datetime.datetime.fromtimestamp(ts)    \n",
    "bucket_name2 = 'csv101'\n",
    "bucket2 = conn.create_bucket(bucket_name2)\n",
    "\n",
    "filename = ('ABC.zip')\n",
    "filename_csv = (os.getcwd() + \"/accuracy_error_metrics1.csv\")\n",
    "print(filename)\n",
    "print (\"Created S3 bucket successfully\")\n",
    "\n",
    "def percent_cb(complete, total):\n",
    "    sys.stdout.write('.')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "k = Key(bucket1)\n",
    "k.key = 'ABC'\n",
    "k.set_contents_from_filename(filename,cb=percent_cb, num_cb=10)\n",
    "\n",
    "print(\"File successfully uploaded to S3\")\n",
    "k1 = Key(bucket2)\n",
    "k1.key = 'accuracy.csv'\n",
    "k1.set_contents_from_filename(filename_csv,cb=percent_cb, num_cb=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
